{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "persona-extraction-header",
   "metadata": {},
   "source": [
    "## Persona Info Extraction Pipeline\n",
    "\n",
    "This notebook demonstrates the **persona info extraction pipeline** using the refactored functions from `src/modules/persona_info_extraction/`.\n",
    "\n",
    "### Overview\n",
    "\n",
    "The pipeline implements a **two-phase conversational interview** using LangGraph state machines:\n",
    "\n",
    "1. **Phase 1: Intent & Focus Discovery**\n",
    "   - Collect basic info: name, age, location, languages\n",
    "   - Determine user's intent and current focus (jobs, training, or awareness)\n",
    "   - Identify top professional domain\n",
    "\n",
    "2. **Phase 2: Detailed Extraction** (focus-dependent)\n",
    "   - For job seekers: experience, education, work preferences, skills\n",
    "   - For training seekers: current skills and learning motivations\n",
    "   - For awareness: brief overview\n",
    "\n",
    "3. **Profile Extraction & Validation**\n",
    "   - Extract structured PersonaInfo from conversation transcript\n",
    "   - Validate against domain/skill constraints\n",
    "   - Save to personas map\n",
    "\n",
    "### Features\n",
    "\n",
    "- **Multi-phase interviews** with AWS persona API integration\n",
    "- **Domain-aware validation** using allowed skills mappings\n",
    "- **Carbon emissions tracking** based on token consumption\n",
    "- **Incremental profile building** with resume capability\n",
    "- **Comprehensive logging** and session summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "### 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install LangGraph for state machine management\n",
    "!pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Environment setup\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "# Import pipeline functions\n",
    "from src.modules.persona_info_extraction.pipeline import (\n",
    "    run_interview,\n",
    "    main_interview_pipeline,\n",
    "    load_all_personas,\n",
    "    create_persona_summary,\n",
    "    validate_persona_profile,\n",
    "    extract_profile_from_transcript\n",
    ")\n",
    "\n",
    "# Import agent and configuration\n",
    "from src.agents import get_agent\n",
    "from src.config import (\n",
    "    KNOWN_JOB_DOMAINS,\n",
    "    EDU_LEVELS,\n",
    "    SKILL_LEVELS,\n",
    "    ALLOWED_SKILLS,\n",
    "    CurrentFocus,\n",
    "    WorkType\n",
    ")\n",
    "\n",
    "# Models for type checking\n",
    "from src.modules.persona_info_extraction.models import PersonaInfo, InterviewState\n",
    "\n",
    "print(\"‚úì Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display configuration\n",
    "print(f\"Known Job Domains: {len(KNOWN_JOB_DOMAINS)} domains\")\n",
    "print(f\"Allowed Skills: {sum(len(skills) for skills in ALLOWED_SKILLS.values())} total skills across domains\")\n",
    "print(f\"Education Levels: {len(EDU_LEVELS)} levels\")\n",
    "print(f\"Skill Levels: {SKILL_LEVELS}\")\n",
    "print(f\"\\nExample domains: {list(KNOWN_JOB_DOMAINS)[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "schema-header",
   "metadata": {},
   "source": [
    "### 2. PersonaInfo Schema\n",
    "\n",
    "View the data model for extracted persona profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display PersonaInfo schema\n",
    "print(json.dumps(PersonaInfo.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interview-header",
   "metadata": {},
   "source": [
    "### 3. Run Single Persona Interview\n",
    "\n",
    "Run a complete interview for a single persona using the main pipeline function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure interview parameters\n",
    "PERSONA_ID = \"persona_001\"\n",
    "MODEL_ID = \"mistral-small-latest\"\n",
    "MAX_TURNS_P1 = 5  # Phase 1: Intent & Focus\n",
    "MAX_TURNS_P2 = 5  # Phase 2: Detailed Extraction\n",
    "\n",
    "# Run interview\n",
    "print(f\"Starting interview for {PERSONA_ID}...\\n\")\n",
    "\n",
    "result = main_interview_pipeline(\n",
    "    persona_id=PERSONA_ID,\n",
    "    get_agent=get_agent,\n",
    "    model_id=MODEL_ID,\n",
    "    max_turns_p1=MAX_TURNS_P1,\n",
    "    max_turns_p2=MAX_TURNS_P2\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERVIEW COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "if \"error\" in result:\n",
    "    print(f\"‚ùå Interview failed: {result['error']}\")\n",
    "else:\n",
    "    profile = result[\"profile\"]\n",
    "    validation = result[\"validation\"]\n",
    "    \n",
    "    print(f\"‚úì Profile extracted for: {profile.get('full_name', 'Unknown')}\")\n",
    "    print(f\"‚úì Saved to: {result['save_path']}\")\n",
    "    print(f\"\\nValidation: {'PASSED ‚úì' if validation['is_valid'] else 'FAILED ‚úó'}\")\n",
    "    \n",
    "    if not validation['is_valid']:\n",
    "        print(\"Validation errors:\")\n",
    "        for error in validation['errors']:\n",
    "            print(f\"  - {error}\")\n",
    "    \n",
    "    if \"summary\" in result:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PERSONA SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(result[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conversation-header",
   "metadata": {},
   "source": [
    "### 4. View Conversation Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full conversation\n",
    "if \"error\" not in result:\n",
    "    conversation = result.get(\"conversation\", [])\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CONVERSATION TRANSCRIPT\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for i, message in enumerate(conversation, 1):\n",
    "        print(f\"{i}. {message}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"\\nTotal messages: {len(conversation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "profile-details-header",
   "metadata": {},
   "source": [
    "### 5. Detailed Profile Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full profile JSON\n",
    "if \"error\" not in result:\n",
    "    profile = result[\"profile\"]\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"EXTRACTED PROFILE (PersonaInfo)\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print(json.dumps(profile, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # Highlight key fields\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KEY FIELDS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Name: {profile.get('full_name')}\")\n",
    "    print(f\"Age: {profile.get('age')}\")\n",
    "    print(f\"Location: {profile.get('location_city')}, {profile.get('location_country')}\")\n",
    "    print(f\"Domain: {profile.get('top_domain')}\")\n",
    "    print(f\"Focus: {profile.get('current_focus')}\")\n",
    "    print(f\"Languages: {', '.join(profile.get('languages', []))}\")\n",
    "    print(f\"Education: {profile.get('education_level')}\")\n",
    "    print(f\"Experience: {profile.get('years_experience')} years\")\n",
    "    print(f\"Work Type: {profile.get('preferred_work_type')}\")\n",
    "    print(f\"Open to Relocate: {profile.get('open_to_relocate')}\")\n",
    "    \n",
    "    # Technical skills\n",
    "    tech_skills = profile.get('technical_skills', [])\n",
    "    if tech_skills:\n",
    "        print(f\"\\nTechnical Skills ({len(tech_skills)}):\")\n",
    "        for skill in tech_skills:\n",
    "            print(f\"  - {skill.get('name')} ({skill.get('level')})\")\n",
    "    \n",
    "    # Training motivation\n",
    "    training = profile.get('training_motivation', [])\n",
    "    if training:\n",
    "        print(f\"\\nTraining Motivation ({len(training)}):\")\n",
    "        for topic in training:\n",
    "            print(f\"  - {topic}\")\n",
    "    \n",
    "    # Desired roles\n",
    "    roles = profile.get('desired_job_roles', [])\n",
    "    if roles:\n",
    "        print(f\"\\nDesired Job Roles ({len(roles)}):\")\n",
    "        for role in roles:\n",
    "            print(f\"  - {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "session-stats-header",
   "metadata": {},
   "source": [
    "### 6. Session Statistics & Emissions Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-session-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display session summary\n",
    "if \"error\" not in result:\n",
    "    session_summary = result.get(\"session_summary\", {})\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"SESSION STATISTICS\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print(f\"Persona ID: {session_summary.get('persona_id')}\")\n",
    "    print(f\"Model: {session_summary.get('model')}\")\n",
    "    print(f\"Total Turns: {session_summary.get('total_turns')}\")\n",
    "    print(f\"Conversation IDs: {len(session_summary.get('conversation_ids', []))}\")\n",
    "    \n",
    "    # Token usage\n",
    "    meta = result.get(\"final_state\", {}).get(\"meta\", {})\n",
    "    if meta:\n",
    "        print(f\"\\nüìä Token Usage:\")\n",
    "        print(f\"  Total Input Tokens: {meta.get('total_input_tokens', 0):,}\")\n",
    "        print(f\"  Total Output Tokens: {meta.get('total_output_tokens', 0):,}\")\n",
    "        print(f\"  Total Tokens: {meta.get('total_input_tokens', 0) + meta.get('total_output_tokens', 0):,}\")\n",
    "        \n",
    "        # Emissions tracking\n",
    "        if 'carbon_emissions_g' in meta:\n",
    "            print(f\"\\nüå± Carbon Emissions:\")\n",
    "            print(f\"  CO2 Equivalent: {meta.get('carbon_emissions_g', 0):.4f} grams\")\n",
    "            print(f\"  (Based on token consumption)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-header",
   "metadata": {},
   "source": [
    "### 7. Batch Processing Multiple Personas\n",
    "\n",
    "Process multiple personas in batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch process personas\n",
    "PERSONA_IDS = [\"persona_001\", \"persona_002\", \"persona_003\"]  # Update with actual IDs\n",
    "BATCH_RESULTS = []\n",
    "\n",
    "print(f\"Processing {len(PERSONA_IDS)} personas...\\n\")\n",
    "\n",
    "for i, persona_id in enumerate(PERSONA_IDS, 1):\n",
    "    print(f\"[{i}/{len(PERSONA_IDS)}] Interviewing {persona_id}...\", end=\" \")\n",
    "    \n",
    "    result = main_interview_pipeline(\n",
    "        persona_id=persona_id,\n",
    "        get_agent=get_agent,\n",
    "        model_id=\"mistral-small-latest\",\n",
    "        max_turns_p1=5,\n",
    "        max_turns_p2=5\n",
    "    )\n",
    "    \n",
    "    BATCH_RESULTS.append(result)\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        print(f\"‚ùå FAILED: {result['error']}\")\n",
    "    else:\n",
    "        profile = result[\"profile\"]\n",
    "        name = profile.get(\"full_name\", \"Unknown\")\n",
    "        is_valid = result[\"validation\"][\"is_valid\"]\n",
    "        status = \"‚úì\" if is_valid else \"‚úó\"\n",
    "        print(f\"{status} {name}\")\n",
    "\n",
    "print(f\"\\nBatch processing complete!\")\n",
    "print(f\"Success: {sum(1 for r in BATCH_RESULTS if 'error' not in r)}/{len(BATCH_RESULTS)}\")\n",
    "print(f\"Failed: {sum(1 for r in BATCH_RESULTS if 'error' in r)}/{len(BATCH_RESULTS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display batch summary\n",
    "print(\"=\"*80)\n",
    "print(\"BATCH SUMMARY\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for i, result in enumerate(BATCH_RESULTS, 1):\n",
    "    if \"error\" not in result:\n",
    "        profile = result[\"profile\"]\n",
    "        print(f\"{i}. {profile.get('full_name')}\")\n",
    "        print(f\"   Domain: {profile.get('top_domain')}\")\n",
    "        print(f\"   Focus: {profile.get('current_focus')}\")\n",
    "        print(f\"   Skills: {len(profile.get('technical_skills', []))}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-personas-header",
   "metadata": {},
   "source": [
    "### 8. Load All Saved Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-all-personas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all personas from today's session\n",
    "all_personas = load_all_personas()\n",
    "\n",
    "print(f\"Loaded {len(all_personas)} personas from storage\\n\")\n",
    "\n",
    "# Display summary\n",
    "for persona_id, persona_data in list(all_personas.items())[:5]:  # Show first 5\n",
    "    profile = persona_data.get(\"profile\", {})\n",
    "    print(f\"ID: {persona_id}\")\n",
    "    print(f\"  Name: {profile.get('full_name', 'Unknown')}\")\n",
    "    print(f\"  Domain: {profile.get('top_domain', 'unspecified')}\")\n",
    "    print(f\"  Focus: {profile.get('current_focus', 'unspecified')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extract-from-transcript-header",
   "metadata": {},
   "source": [
    "### 9. Extract Profile from Existing Transcript\n",
    "\n",
    "If you have an existing conversation transcript, you can extract the profile directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-from-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extract profile from transcript\n",
    "sample_transcript = \"\"\"\n",
    "Assistant: Hello! I'm here to help you find job opportunities and training programs. What's your full name?\n",
    "User: My name is Maria Silva.\n",
    "Assistant: Nice to meet you, Maria! How old are you?\n",
    "User: I'm 28 years old.\n",
    "Assistant: Great! What city are you currently in?\n",
    "User: I'm in S√£o Paulo, Brazil.\n",
    "Assistant: What are your main goals right now? Are you looking for jobs, training, or just exploring?\n",
    "User: I want to find a job and also get some training to improve my skills.\n",
    "Assistant: Excellent! What professional domain are you most interested in?\n",
    "User: I'm interested in the Food Industry.\n",
    "\"\"\"\n",
    "\n",
    "# Extract profile\n",
    "extractor_agent = get_agent(\"extractor\")\n",
    "extracted_profile = extract_profile_from_transcript(\n",
    "    transcript=sample_transcript,\n",
    "    extractor_agent=extractor_agent,\n",
    "    domain=\"Food Industry\",\n",
    "    intent=\"Find job and training\",\n",
    "    focus=\"jobs+trainings\"\n",
    ")\n",
    "\n",
    "print(\"Extracted Profile:\")\n",
    "print(json.dumps(extracted_profile, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-header",
   "metadata": {},
   "source": [
    "### 10. Profile Validation\n",
    "\n",
    "Validate a persona profile manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate a profile\n",
    "if \"error\" not in result:\n",
    "    profile_to_validate = result[\"profile\"]\n",
    "    \n",
    "    is_valid, errors = validate_persona_profile(profile_to_validate)\n",
    "    \n",
    "    print(\"Profile Validation:\")\n",
    "    print(f\"Status: {'VALID ‚úì' if is_valid else 'INVALID ‚úó'}\")\n",
    "    \n",
    "    if not is_valid:\n",
    "        print(\"\\nErrors found:\")\n",
    "        for error in errors:\n",
    "            print(f\"  - {error}\")\n",
    "    else:\n",
    "        print(\"\\nProfile passed all validation checks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "### 11. Export Results\n",
    "\n",
    "Export personas for downstream processing (knowledge graph, recommendations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all personas to JSON\n",
    "output_dir = Path(\"../processed_data/outputs\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "export_file = output_dir / f\"personas_extracted_{datetime.now().strftime('%Y-%m-%d')}.json\"\n",
    "\n",
    "# Collect all valid profiles\n",
    "valid_personas = {}\n",
    "for result in BATCH_RESULTS:\n",
    "    if \"error\" not in result and result[\"validation\"][\"is_valid\"]:\n",
    "        persona_id = result[\"final_state\"].get(\"persona_id\")\n",
    "        valid_personas[persona_id] = result[\"profile\"]\n",
    "\n",
    "# Save to file\n",
    "with open(export_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(valid_personas, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úì Exported {len(valid_personas)} personas to: {export_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
