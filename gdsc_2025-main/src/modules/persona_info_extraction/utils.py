"""
Utility functions for persona info extraction.
Extracted from PersonaInfo_Extraction.ipynb notebook.
"""

import json
import re
from typing import List, Dict, Any, Optional

# Constants
FOCUS_JOB = "jobs+trainings"
FOCUS_TRAINING = "training_only"
FOCUS_AWARENESS = "awareness"

LEVEL_MAP = {
    "basic": "Basic",
    "intermediate": "Intermediate", 
    "advanced": "Advanced",
    "1": "Basic", "2": "Intermediate", "3": "Advanced",
    "junior": "Basic", "mid": "Intermediate", "senior": "Advanced",
}

LANG_CODE_MAP = {
    # Portuguese
    "portuguese": "pt-br", "pt": "pt-br", "pt-br": "pt-br", "ptbr": "pt-br", "br portuguese": "pt-br",
    "brazilian portuguese": "pt-br", "português": "pt-br", "português do brasil": "pt-br",
    # English
    "english": "en", "en": "en", "inglês": "en",
    # Spanish (use if needed)
    "spanish": "es", "español": "es", "es": "es",
    # Add more as needed...
}


def safe_json_from_text(s: str) -> dict:
    """Safe JSON parsing from text with fallbacks."""
    if not s:
        return {}
    s = re.sub(r"^```(json)?\n|```$", "", s.strip(), flags=re.MULTILINE)
    m = re.search(r"\{.*\}", s, flags=re.DOTALL)
    if not m:
        return {}
    try:
        return json.loads(m.group(0))
    except Exception:
        return {}


def bullet_list(skills: List[str]) -> str:
    """Convert list of skills to bullet point format."""
    return "\n".join(f"- {s}" for s in skills)


def to_comma_list(items: list[str]) -> str:
    """Convert list to comma-separated string."""
    # Localize this joiner if needed (e.g., using " · " or localized comma/and rules)
    return ", ".join(items)


def to_bulleted(items: list[str]) -> str:
    """Convert list to bullet point format."""
    # Localize bullet symbol if needed
    return "\n".join(f"- {x}" for x in items)


def clean_no_phase3_or_offers(text: str) -> str:
    """
    Remove references to Phase 3 and neutralize job-offer pitches.
    Does not alter the substance of content-collection questions.
    """
    if not text:
        return text

    cleaned = text

    # Remove explicit "Phase 3" sections or headlines.
    cleaned = re.sub(r"(?im)^\s*[*-]*\s*phase\s*3\b.*$", "", cleaned)
    cleaned = re.sub(r"(?i)\bphase\s*3\b", "", cleaned)

    # Remove "we'll move to phase 3" style lines.
    cleaned = re.sub(r"(?im)^\s*we('|\s)ll.*phase\s*3.*$", "", cleaned)

    # Neutralize direct job offers; keep it informational
    cleaned = re.sub(r"(?i)\b(I can|get|will)\s+(get you|send you|provide|line up)\s+(a|some)\s+(job|offer|offers)\b.*", 
                     "I will focus on guidance and training information; no direct job offers will be discussed.", 
                     cleaned)

    # Trim excess blank lines generated by removals
    cleaned = re.sub(r"\n{3,}", "\n\n", cleaned).strip()
    return cleaned


def normalize_focus(text: Optional[str]) -> Optional[str]:
    """Map natural phrases to canonical routing tokens. Keep user-facing tone elsewhere."""
    if not text:
        return None
    t = (text or "").strip().lower()
    if any(k in t for k in ["job", "full-time", "full time", "hire", "hiring", "find a role", "finding a job"]):
        return FOCUS_JOB
    if "training_only" in t or "training only" in t or "upskill" in t or "train" in t:
        return FOCUS_TRAINING
    if "awareness" in t or "explore" in t or "just looking" in t:
        return FOCUS_AWARENESS
    if t in {FOCUS_JOB, FOCUS_TRAINING, FOCUS_AWARENESS}:
        return t
    return None


def to_language_codes(items: list[str]) -> list[str]:
    """
    Map free-text languages to canonical short codes. Dedup while preserving order.
    Unknown entries are kept as-is if they already look like a short code, otherwise dropped.
    """
    out, seen = [], set()
    for raw in items or []:
        s = (raw or "").strip()
        if not s:
            continue
        key = s.lower()
        code = LANG_CODE_MAP.get(key)
        if code is None:
            # Keep short-looking codes such as "en-GB" or "de" if user typed them.
            if 2 <= len(s) <= 5 or "-" in s:
                code = s.lower()
            else:
                # Skip long names we don't recognize, to avoid noisy values.
                continue
        if code not in seen:
            seen.add(code)
            out.append(code)
    return out


def sanitize_domain(val: str | None, known_domains: list[str]) -> str:
    """
    Accept domain only if it matches exactly one of known_domains.
    Anything else returns 'unspecified'.
    """
    v = (val or "").strip()
    return v if v in known_domains else "unspecified"


def _normalize_skill_name(s: str) -> str:
    """Normalize skill name by converting to lowercase and joining split words."""
    return " ".join(str(s).strip().lower().split())


def _dedup_preserve_order(items: List[Any]) -> List[Any]:
    """Remove duplicates from list while preserving order."""
    seen = set()
    out = []
    for x in items:
        if x not in seen:
            seen.add(x)
            out.append(x)
    return out


def _coerce_level(s: Any) -> str:
    """Convert various level representations to standardized Basic/Intermediate/Advanced."""
    if not s: 
        return "Basic"
    t = str(s).strip().lower()
    return LEVEL_MAP.get(t, "Basic")